{"ast":null,"code":"'use strict';\n\nconst CID = require('cids');\n\nconst protobuf = require('protons');\n\nconst fnv1a = require('fnv1a');\n\nconst varint = require('varint');\n\nconst dagpb = require('ipld-dag-pb');\n\nconst DAGNode = dagpb.DAGNode,\n      DAGLink = dagpb.DAGLink;\n\nconst multicodec = require('multicodec');\n\nconst pbSchema = require('./pin.proto');\n\nconst _require = require('./utils'),\n      cidToKey = _require.cidToKey,\n      DEFAULT_FANOUT = _require.DEFAULT_FANOUT,\n      MAX_ITEMS = _require.MAX_ITEMS,\n      EMPTY_KEY = _require.EMPTY_KEY;\n\nconst uint8ArrayConcat = require('uint8arrays/concat');\n\nconst uint8ArrayCompare = require('uint8arrays/compare');\n\nconst uint8ArrayToString = require('uint8arrays/to-string');\n\nconst uint8ArrayFromString = require('uint8arrays/from-string');\n\nconst uint8ArrayEquals = require('uint8arrays/equals');\n\nconst pb = protobuf(pbSchema);\n\nfunction toB58String(hash) {\n  return new CID(hash).toBaseEncodedString();\n}\n\nfunction readHeader(rootNode) {\n  // rootNode.data should be a buffer of the format:\n  // < varint(headerLength) | header | itemData... >\n  const rootData = rootNode.Data;\n  const hdrLength = varint.decode(rootData);\n  const vBytes = varint.decode.bytes;\n\n  if (vBytes <= 0) {\n    throw new Error('Invalid Set header length');\n  }\n\n  if (vBytes + hdrLength > rootData.length) {\n    throw new Error('Impossibly large set header length');\n  }\n\n  const hdrSlice = rootData.slice(vBytes, hdrLength + vBytes);\n  const header = pb.Set.decode(hdrSlice);\n\n  if (header.version !== 1) {\n    throw new Error(\"Unsupported Set version: \".concat(header.version));\n  }\n\n  if (header.fanout > rootNode.Links.length) {\n    throw new Error('Impossibly large fanout');\n  }\n\n  return {\n    header: header,\n    data: rootData.slice(hdrLength + vBytes)\n  };\n}\n\nfunction hash(seed, key) {\n  const buffer = new Uint8Array(4);\n  const dataView = new DataView(buffer.buffer);\n  dataView.setUint32(0, seed, true);\n  const encodedKey = uint8ArrayFromString(toB58String(key));\n  const data = uint8ArrayConcat([buffer, encodedKey], buffer.byteLength + encodedKey.byteLength);\n  return fnv1a(uint8ArrayToString(data));\n}\n\nasync function* walkItems(blockstore, node) {\n  const pbh = readHeader(node);\n  let idx = 0;\n\n  for (const link of node.Links) {\n    if (idx < pbh.header.fanout) {\n      // the first pbh.header.fanout links are fanout bins\n      // if a fanout bin is not 'empty', dig into and walk its DAGLinks\n      const linkHash = link.Hash;\n\n      if (!uint8ArrayEquals(EMPTY_KEY, linkHash.bytes)) {\n        // walk the links of this fanout bin\n        const buf = await blockstore.get(cidToKey(linkHash));\n        const node = dagpb.util.deserialize(buf);\n        yield* walkItems(blockstore, node);\n      }\n    } else {\n      // otherwise, the link is a pin\n      yield link.Hash;\n    }\n\n    idx++;\n  }\n}\n\nasync function* loadSet(blockstore, rootNode, name) {\n  const link = rootNode.Links.find(l => l.Name === name);\n\n  if (!link) {\n    throw new Error('No link found with name ' + name);\n  }\n\n  const buf = await blockstore.get(cidToKey(link.Hash));\n  const node = dagpb.util.deserialize(buf);\n  yield* walkItems(blockstore, node);\n}\n\nfunction storeItems(blockstore, items) {\n  return storePins(items, 0);\n\n  async function storePins(pins, depth) {\n    const pbHeader = pb.Set.encode({\n      version: 1,\n      fanout: DEFAULT_FANOUT,\n      seed: depth\n    });\n    const header = varint.encode(pbHeader.length);\n    const headerBuf = uint8ArrayConcat([header, pbHeader]);\n    const fanoutLinks = [];\n\n    for (let i = 0; i < DEFAULT_FANOUT; i++) {\n      fanoutLinks.push(new DAGLink('', 1, EMPTY_KEY));\n    }\n\n    if (pins.length <= MAX_ITEMS) {\n      const nodes = pins.map(item => {\n        return {\n          link: new DAGLink('', 1, item.key),\n          data: item.data || new Uint8Array()\n        };\n      }) // sorting makes any ordering of `pins` produce the same DAGNode\n      .sort((a, b) => {\n        return uint8ArrayCompare(a.link.Hash.bytes, b.link.Hash.bytes);\n      });\n      const rootLinks = fanoutLinks.concat(nodes.map(item => item.link));\n      const rootData = uint8ArrayConcat([headerBuf, ...nodes.map(item => item.data)]);\n      return new DAGNode(rootData, rootLinks);\n    } else {\n      // If the array of pins is > MAX_ITEMS, we:\n      //  - distribute the pins among `DEFAULT_FANOUT` bins\n      //    - create a DAGNode for each bin\n      //      - add each pin as a DAGLink to that bin\n      //  - create a root DAGNode\n      //    - add each bin as a DAGLink\n      //  - send that root DAGNode via callback\n      // (using go-ipfs' \"wasteful but simple\" approach for consistency)\n      // https://github.com/ipfs/go-ipfs/blob/master/pin/set.go#L57\n      const bins = pins.reduce((bins, pin) => {\n        const n = hash(depth, pin.key) % DEFAULT_FANOUT;\n        bins[n] = n in bins ? bins[n].concat([pin]) : [pin];\n        return bins;\n      }, []);\n      let idx = 0;\n\n      for (const bin of bins) {\n        const child = await storePins(bin, depth + 1);\n        await storeChild(child, idx);\n        idx++;\n      }\n\n      return new DAGNode(headerBuf, fanoutLinks);\n    }\n\n    async function storeChild(child, binIdx) {\n      const buf = dagpb.util.serialize(child);\n      const cid = await dagpb.util.cid(buf, {\n        cidVersion: 0,\n        hashAlg: multicodec.SHA2_256\n      });\n      await blockstore.put(cidToKey(cid), buf);\n      fanoutLinks[binIdx] = new DAGLink('', child.size, cid);\n    }\n  }\n}\n\nasync function storeSet(blockstore, type, cids) {\n  const rootNode = await storeItems(blockstore, cids.map(cid => {\n    return {\n      key: cid,\n      data: null\n    };\n  }));\n  const buf = rootNode.serialize(rootNode);\n  const cid = await dagpb.util.cid(buf, {\n    cidVersion: 0,\n    hashAlg: multicodec.SHA2_256\n  });\n  await blockstore.put(cidToKey(cid), buf);\n  return new DAGLink(type, rootNode.size, cid);\n}\n\nmodule.exports = {\n  loadSet,\n  storeSet\n};","map":null,"metadata":{},"sourceType":"script"}