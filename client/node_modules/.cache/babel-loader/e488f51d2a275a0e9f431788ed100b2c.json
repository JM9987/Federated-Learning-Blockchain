{"ast":null,"code":"'use strict';\n\nconst importer = require('ipfs-unixfs-importer');\n\nconst normaliseAddInput = require('ipfs-core-utils/src/files/normalise-input/index');\n\nconst _require = require('./utils'),\n      parseChunkerString = _require.parseChunkerString;\n\nconst _require2 = require('it-pipe'),\n      pipe = _require2.pipe;\n\nconst withTimeoutOption = require('ipfs-core-utils/src/with-timeout-option');\n\nconst mergeOptions = require('merge-options').bind({\n  ignoreUndefined: true\n});\n/**\n * @typedef {Object} Context\n * @property {import('..').Block} block\n * @property {import('..').GCLock} gcLock\n * @property {import('..').Preload} preload\n * @property {import('..').Pin} pin\n * @property {import('ipfs-core-types/src/root').ShardingOptions} [options]\n *\n * @param {Context} context\n */\n\n\nmodule.exports = ({\n  block,\n  gcLock,\n  preload,\n  pin,\n  options\n}) => {\n  const isShardingEnabled = options && options.sharding;\n  /**\n   * Import multiple files and data into IPFS.\n   *\n   * @param {import('ipfs-core-types/src/files').ImportSource} source\n   * @param {import('ipfs-core-types/src/root').AddAllOptions} [options]\n   * @returns {AsyncIterable<import('ipfs-core-types/src/files').UnixFSEntry>}\n   */\n\n  async function* addAll(source, options = {}) {\n    const opts = mergeOptions({\n      shardSplitThreshold: isShardingEnabled ? 1000 : Infinity,\n      strategy: 'balanced'\n    }, options, { ...parseChunkerString(options.chunker)\n    }); // CID v0 is for multihashes encoded with sha2-256\n\n    if (opts.hashAlg && opts.hashAlg !== 'sha2-256' && opts.cidVersion !== 1) {\n      opts.cidVersion = 1;\n    }\n\n    if (opts.trickle) {\n      opts.strategy = 'trickle';\n    }\n\n    if (opts.strategy === 'trickle') {\n      opts.leafType = 'raw';\n      opts.reduceSingleLeafToSelf = false;\n    }\n\n    if (opts.cidVersion > 0 && opts.rawLeaves === undefined) {\n      // if the cid version is 1 or above, use raw leaves as this is\n      // what go does.\n      opts.rawLeaves = true;\n    }\n\n    if (opts.hashAlg !== undefined && opts.rawLeaves === undefined) {\n      // if a non-default hash alg has been specified, use raw leaves as this is\n      // what go does.\n      opts.rawLeaves = true;\n    }\n\n    delete opts.trickle;\n    const totals = {};\n\n    if (opts.progress) {\n      const prog = opts.progress;\n\n      opts.progress = (bytes, path) => {\n        if (!totals[path]) {\n          totals[path] = 0;\n        }\n\n        totals[path] += bytes;\n        prog(totals[path], path);\n      };\n    }\n\n    const iterator = pipe(normaliseAddInput(source), source => importer(source, block, { ...opts,\n      pin: false\n    }), transformFile(opts), preloadFile(preload, opts), pinFile(pin, opts));\n    const releaseLock = await gcLock.readLock();\n\n    try {\n      for await (const added of iterator) {\n        // do not keep file totals around forever\n        delete totals[added.path];\n        yield added;\n      }\n    } finally {\n      releaseLock();\n    }\n  }\n\n  return withTimeoutOption(addAll);\n};\n\nfunction transformFile(opts) {\n  return async function* (source) {\n    for await (const file of source) {\n      let cid = file.cid;\n\n      if (opts.cidVersion === 1) {\n        cid = cid.toV1();\n      }\n\n      let path = file.path ? file.path : cid.toString();\n\n      if (opts.wrapWithDirectory && !file.path) {\n        path = '';\n      }\n\n      yield {\n        path,\n        cid,\n        size: file.size,\n        mode: file.unixfs && file.unixfs.mode,\n        mtime: file.unixfs && file.unixfs.mtime\n      };\n    }\n  };\n}\n\nfunction preloadFile(preload, opts) {\n  return async function* (source) {\n    for await (const file of source) {\n      const isRootFile = !file.path || opts.wrapWithDirectory ? file.path === '' : !file.path.includes('/');\n      const shouldPreload = isRootFile && !opts.onlyHash && opts.preload !== false;\n\n      if (shouldPreload) {\n        preload(file.cid);\n      }\n\n      yield file;\n    }\n  };\n}\n\nfunction pinFile(pin, opts) {\n  return async function* (source) {\n    for await (const file of source) {\n      // Pin a file if it is the root dir of a recursive add or the single file\n      // of a direct add.\n      const isRootDir = !file.path.includes('/');\n      const shouldPin = (opts.pin == null ? true : opts.pin) && isRootDir && !opts.onlyHash;\n\n      if (shouldPin) {\n        // Note: addAsyncIterator() has already taken a GC lock, so tell\n        // pin.add() not to take a (second) GC lock\n        await pin.add(file.cid, {\n          preload: false,\n          lock: false\n        });\n      }\n\n      yield file;\n    }\n  };\n}","map":null,"metadata":{},"sourceType":"script"}